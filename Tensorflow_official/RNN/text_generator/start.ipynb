{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "file_path = keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "1115394"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open(file_path, 'rb').read().decode(encoding='utf-8')\n",
    "len(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 有 100 多万个字母的数据集，打印前 1000 个。\n",
    "print(text[:1000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    },
    {
     "data": {
      "text/plain": "65"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取出不重复的字母\n",
    "vocab = sorted(set(text))\n",
    "print(vocab)\n",
    "len(vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([18, 47, 56, ..., 45,  8,  0])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2index = {u:i for i, u in enumerate(vocab)}\n",
    "index2char = np.array(vocab)\n",
    "\n",
    "# 把字符都转成索引\n",
    "text_as_int = np.array([char2index[c] for c in text])\n",
    "text_as_int"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 嵌入的维度\n",
    "embedding_dimension = 256\n",
    "\n",
    "# RNN 单元数量\n",
    "rnn_units = 1024\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(len(vocab), embedding_dimension,\n",
    "                           batch_input_shape=[1, None]),\n",
    "    keras.layers.GRU(rnn_units,\n",
    "                     return_sequences=True,\n",
    "                     stateful=True,\n",
    "                     recurrent_initializer='glorot_uniform'),\n",
    "    keras.layers.Dense(len(vocab))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    # 因为我们的模型返回逻辑回归，所以我们需要设定命令行参数 from_logits\n",
    "    return keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model.load_weights('04-14-10-05.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 4,021,569\n",
      "Trainable params: 4,021,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def generate_text(start_string, temperature=1.0):\n",
    "    \"\"\"\n",
    "    temperature:\n",
    "    # 低温度会生成更可预测的文本\n",
    "    # 较高温度会生成更令人惊讶的文本\n",
    "    # 可以通过试验以找到最好的设定\n",
    "    \"\"\"\n",
    "    # 评估步骤（用学习过的模型生成文本）\n",
    "\n",
    "    # 要生成的字符个数\n",
    "    num_generate = 1000\n",
    "\n",
    "    # 将起始字符串转换为数字（向量化）\n",
    "    input_eval = [char2index[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # 空字符串用于存储结果\n",
    "    text_generated = []\n",
    "\n",
    "    # 这里批大小为 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # 删除批次的维度\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "          # 用分类分布预测模型返回的字符\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # 把预测字符和前面的隐藏状态一起传递给模型作为下一个输入\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(index2char[predicted_id])\n",
    "\n",
    "    return start_string + ''.join(text_generated)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: I have made-foot to him:\n",
      "And let lame the rexeit remains,\n",
      "Not so your majesty to Stuff we twice with\n",
      "set to do it. or haste thy Good,\n",
      "Go thou tender holidably showe; though stand, within, yes, my lords;\n",
      "But thou hast plainer into the body to him with his\n",
      "to the morning presus: where are ammourage hath,\n",
      "No iscuse; and my lords,\n",
      "I would have for justice should be, my true lenatively\n",
      "To sworn a toport letign:\n",
      "Come youngley sorrow?\n",
      "\n",
      "Second must deliver you.\n",
      "You long lour's revolquest, was, dellits and 'tis so put with him,\n",
      "And all thy suconduttless peace by this:\n",
      "\n",
      "TRANIO:\n",
      "But say no hollow, imprisonment I have answer to you\n",
      "Wo make; which was but outurnedor,\n",
      "Do pon by any other water, he speakshe mut of haste,\n",
      "His fire and sad their common world we long as\n",
      "on denial, 'tis an English knights:\n",
      "O my hoped livery, this shall answer our presented.\n",
      "\n",
      "PETRUCHIO:\n",
      "Readle country, what were it, and he:\n",
      "Be, if thou stay, so you might consul!\n",
      "\n",
      "GREMIO:\n",
      "As, leisure, I beseech love be a\n",
      "fought in being bl\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(start_string=\"ROMEO: \"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}